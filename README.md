# PenphinMind

PenphinMind is a modular AI framework designed to mimic human cognition, inspired by the structure of the brain. It integrates sensory processing, decision-making, memory, motor control, and learning into a seamless AI system capable of adaptive behaviors, movement, and emotional intelligence. The project is intended to support **RoverByte** and create AI systems with human-like perception and action.

## Features

- **Multimodal Sensory Processing**: Vision, sound, and touch integration.
- **Cognitive Decision-Making**: Adaptive decision-making based on emotion, context, and learning.
- **Memory Systems**: Hierarchical memory that stores experiences and learns over time.
- **Motor Control & Coordination**: AI-driven motion planning, execution, and real-time feedback.
- **Behavioral Adaptation**: Reinforcement learning and emotional regulation.

## Whitepapers

PenphinMind's development is detailed in the following whitepapers:

1. [Modular Cognitive Framework in Code](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/0%20-%20Modular%20Cognitive%20Framework%20in%20Code.md)
2. [PenphinMind - A Modular Cognitive Framework](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/1%20-%20PenphinMind%20-%20A%20Modular%20Cognitive%20Framework.md)
3. [Sensory Processing in AI – Vision, Sound, and Touch](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/2%20-%20Sensory%20Processing%20in%20AI%20-%20Vision%2C%20Sound%2C%20and%20Touch.md)
4. [Decision-Making & Behavioral Regulation in AI](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/3%20-%20Decision-Making%20%26%20Behavioral%20Regulation%20in%20AI.md)
5. [AI Memory Systems – Learning, Adaptation, and Recall](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/4%20-%20AI%20Memory%20Systems%20-%20Learning%2C%20Adaptation%2C%20and%20Recall.md)
6. [Motor Control & Coordination in AI Systems](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/5%20-%20Motor%20Control%20%26%20Coordination%20in%20AI%20Systems.md)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/PenphinMind.git
cd PenphinMind
```
	2.	Create and activate a virtual environment:

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

	3.	Install dependencies:

pip install -r requirements.txt

	4.	Configure your environment:

	•	Copy .env.example to .env
	•	Add your API keys for OpenAI and ElevenLabs

Usage

Run the system:

python runPenphinMind.py

Project Structure
	•	AuditoryCortex/: Speech and audio processing
	•	CorpusCallosum/: Neural command processing
	•	FrontalLobe/: Decision making and planning
	•	Hippocampus/: Memory management
	•	OccipitalLobe/: Visual processing
	•	ParietalLobe/: Sensory integration
	•	TemporalLobe/: Language and audio understanding
	•	MotorCortex/: Movement planning and motor control
	•	Cerebellum/: Learning and adaptation
	•	LimbicSystem/: Emotional processing and motivation
	•	VestibularSystem/: Balance and spatial awareness

License

MIT License - see LICENSE file for details

### Key Updates:
- **Fixed Links**: The links to the whitepapers are now correctly pointing to the respective files in the **PenphinMind** repository.
