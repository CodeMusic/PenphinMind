Here’s an updated version of your README.md for PenphinMind, reflecting the changes discussed and including the whitepapers:

# PenphinMind

PenphinMind is a modular AI framework designed to mimic human cognition, inspired by the structure of the brain. It integrates sensory processing, decision-making, memory, motor control, and learning into a seamless AI system capable of adaptive behaviors, movement, and emotional intelligence. The project is intended to support **RoverByte** and create AI systems with human-like perception and action.

## Features

- **Multimodal Sensory Processing**: Vision, sound, and touch integration.
- **Cognitive Decision-Making**: Adaptive decision-making based on emotion, context, and learning.
- **Memory Systems**: Hierarchical memory that stores experiences and learns over time.
- **Motor Control & Coordination**: AI-driven motion planning, execution, and real-time feedback.
- **Behavioral Adaptation**: Reinforcement learning and emotional regulation.

## Whitepapers

PenphinMind's development is detailed in the following whitepapers:

1. [Modular Cognitive Framework in Code](whitepapers/0-Modular_Cognitive_Framework_in_Code.md)
2. [PenphinMind - A Modular Cognitive Framework](whitepapers/1-PenphinMind_-_A_Modular_Cognitive_Framework.md)
3. [Sensory Processing in AI – Vision, Sound, and Touch](whitepapers/2-Sensory_Processing_in_AI_-_Vision,_Sound,_and_Touch.md)
4. [Decision-Making & Behavioral Regulation in AI](whitepapers/3-Decision-Making_&_Behavioral_Regulation_in_AI.md)
5. [AI Memory Systems – Learning, Adaptation, and Recall](whitepapers/4-AI_Memory_Systems_-_Learning,_Adaptation,_and_Recall.md)
6. [Motor Control & Coordination in AI Systems](whitepapers/5-Motor_Control_&_Coordination_in_AI_Systems.md)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/PenphinMind.git
cd PenphinMind
```
	2.	Create and activate a virtual environment:

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

	3.	Install dependencies:

pip install -r requirements.txt

	4.	Configure your environment:

	•	Copy .env.example to .env
	•	Add your API keys for OpenAI and ElevenLabs

Usage

Run the system:

python runPenphinMind.py

Project Structure
	•	AuditoryCortex/: Speech and audio processing
	•	CorpusCallosum/: Neural command processing
	•	FrontalLobe/: Decision making and planning
	•	Hippocampus/: Memory management
	•	OccipitalLobe/: Visual processing
	•	ParietalLobe/: Sensory integration
	•	TemporalLobe/: Language and audio understanding
	•	MotorCortex/: Movement planning and motor control
	•	Cerebellum/: Learning and adaptation
	•	LimbicSystem/: Emotional processing and motivation
	•	VestibularSystem/: Balance and spatial awareness

License

MIT License - see LICENSE file for details

### Changes Made:

1. **Project Name Update**: The project is now called **PenphinMind**, reflecting the shift to a more holistic AI framework.
2. **Whitepapers**: Links to all the whitepapers are included under the **Whitepapers** section for easy access.
3. **Installation and Usage**: Retained the essential installation steps and usage instructions.
4. **Project Structure**: Expanded the project structure to reflect more comprehensive cognitive functions, such as **MotorCortex**, **Cerebellum**, **LimbicSystem**, and **VestibularSystem**.
