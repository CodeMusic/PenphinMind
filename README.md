Here’s the updated README.md for PenphinMind, with fixed links to the whitepapers:

# PenphinMind

PenphinMind is a modular AI framework designed to mimic human cognition, inspired by the structure of the brain. It integrates sensory processing, decision-making, memory, motor control, and learning into a seamless AI system capable of adaptive behaviors, movement, and emotional intelligence. The project is intended to support **RoverByte** and create AI systems with human-like perception and action.

## Features

- **Multimodal Sensory Processing**: Vision, sound, and touch integration.
- **Cognitive Decision-Making**: Adaptive decision-making based on emotion, context, and learning.
- **Memory Systems**: Hierarchical memory that stores experiences and learns over time.
- **Motor Control & Coordination**: AI-driven motion planning, execution, and real-time feedback.
- **Behavioral Adaptation**: Reinforcement learning and emotional regulation.

## Whitepapers

PenphinMind's development is detailed in the following whitepapers:

1. [Modular Cognitive Framework in Code](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/0-Modular_Cognitive_Framework_in_Code.md)
2. [PenphinMind - A Modular Cognitive Framework](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/1-PenphinMind_-_A_Modular_Cognitive_Framework.md)
3. [Sensory Processing in AI – Vision, Sound, and Touch](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/2-Sensory_Processing_in_AI_-_Vision,_Sound,_and_Touch.md)
4. [Decision-Making & Behavioral Regulation in AI](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/3-Decision-Making_&_Behavioral_Regulation_in_AI.md)
5. [AI Memory Systems – Learning, Adaptation, and Recall](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/4-AI_Memory_Systems_-_Learning,_Adaptation,_and_Recall.md)
6. [Motor Control & Coordination in AI Systems](https://github.com/CodeMusic/PenphinMind/blob/main/whitepapers/5-Motor_Control_&_Coordination_in_AI_Systems.md)

## Installation

1. Clone the repository:
```bash
git clone https://github.com/yourusername/PenphinMind.git
cd PenphinMind
```

	2.	Create and activate a virtual environment:

python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

	3.	Install dependencies:

pip install -r requirements.txt

	4.	Configure your environment:

	•	Copy .env.example to .env
	•	Add your API keys for OpenAI and ElevenLabs

Usage

Run the system:

python runPenphinMind.py

Project Structure
	•	AuditoryCortex/: Speech and audio processing
	•	CorpusCallosum/: Neural command processing
	•	FrontalLobe/: Decision making and planning
	•	Hippocampus/: Memory management
	•	OccipitalLobe/: Visual processing
	•	ParietalLobe/: Sensory integration
	•	TemporalLobe/: Language and audio understanding
	•	MotorCortex/: Movement planning and motor control
	•	Cerebellum/: Learning and adaptation
	•	LimbicSystem/: Emotional processing and motivation
	•	VestibularSystem/: Balance and spatial awareness

License

MIT License - see LICENSE file for details

### Fixes made:
- **Whitepapers Links**: Corrected the URLs to link directly to the **whitepapers** folder in the **PenphinMind** branch on GitHub.
